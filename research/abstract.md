[Submitted on 01 Mar 2023]
Leveraging Large Language Models with LLaMA: Dataset Creation, Weight Merging, Quantization, and Training
Francis LaBounty Jr., Devin Schumacher
In this paper, we present a comprehensive approach to fine-tuning large language models (LLMs) using the LLaMA (Large Language Model Adaptation) framework. We demonstrate how to create finetune datasets, merge adapter weights, quantize models, and train LLMs with LoRA (Low-Rank Adapters). We provide details on gathering samples of inputs and outputs, constructing prompt templates, and training models to complete prompts. We also discuss the use of weight merging for faster inference and quantization for memory-efficient deployment. Our experiments show that our approach is effective in generating high-quality datasets and training LLMs with improved performance.
Subjects: Artificial Intelligence (cs.AI)
Cite as: arXiv:2304.xxxxxx [cs.AI]
(or arXiv:2304.xxxxxxv1 [cs.AI] for this version)

https://doi.org/10.48550/arXiv.2304.xxxxxx
Focus to learn more
Submission history
From: [Author Name] [view email]
[v1] Fri, 21 Apr 2023 [Time] UTC ([File Size] KB)
