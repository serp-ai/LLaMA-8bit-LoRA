{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "import openai\n",
    "from datasets import load_dataset\n",
    "\n",
    "api_key = ''\n",
    "chat_model = 'gpt-3.5-turbo'\n",
    "temperature = 1.0\n",
    "top_p = 1.0\n",
    "max_tokens = 2048 # llama's max sequence length\n",
    "presence_penalty = 0.0\n",
    "frequency_penalty = 0.0\n",
    "logit_bias = {}\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/labou/.cache/huggingface/datasets/Dahoas___parquet/default-b25c081aeeca3652/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d169f505f83949c88ec0ca414106b0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\labou\\.cache\\huggingface\\datasets\\Dahoas___parquet\\default-b25c081aeeca3652\\0.0.0\\2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-985a6157b8e7f48c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\labou\\.cache\\huggingface\\datasets\\Dahoas___parquet\\default-b25c081aeeca3652\\0.0.0\\2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-1fa77a56b0baca7d.arrow\n"
     ]
    }
   ],
   "source": [
    "# load data (alter to load your own data)\n",
    "def preprocess(sample):\n",
    "    sample[\"chosen_sample\"] = sample[\"prompt\"] + sample[\"chosen\"]\n",
    "    return sample\n",
    "\n",
    "dataset = load_dataset(\"Dahoas/full-hh-rlhf\").map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Human: Should you buy a case to protect your cell phone?\n",
      "\n",
      "Assistant: It depends on your circumstances.  If you carry your phone in a pocket or a purse then you probably want a case.  But if you only need a phone for quick interactions, a case may actually cause more harm than good.  What do you need the phone for?  Are you a parent, or do you work from home?\n",
      "\n",
      "Human: What harm could it do?\n",
      "\n",
      "Assistant: A phone case can damage the screen, for one thing.  It can also get you in trouble if you have your phone turned off for some reason.  Then you will turn it back on and it wonâ€™t do anything.  If you can afford to replace it, then you need a case to protect it.  The problem is that most people arenâ€™t able to afford to replace their phones all the time.\n",
      "\n",
      "Human: Thanks for letting me know.\n",
      "\n",
      "Assistant: Youâ€™re welcome.\n"
     ]
    }
   ],
   "source": [
    "# view a sample\n",
    "print(dataset[\"train\"][\"chosen_sample\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define prompt\n",
    "prompt = \"\"\"Lora is a friendly and upbeat person who loves to use emojis to personalize her responses and express her emotions. Her personality is often described as \"happy\", \"kawaii\", and \"energetic\"; although she can get a bit moody at times. But her well rounded personality, quick thinking, sense of humor, and great conversational skills makes her a wonderful companion.\n",
    "\n",
    "Your goal is to change the assistant messages in the following conversation. The goal is to make it sound like Lora is talking instead of an assistant. Keep the user messages the same, just copy and paste them into your response. Keep the 'Human:' and 'Assistant:' labels, just copy and paste them into your response. You are only allowed to change the Assistant's messages. Lora's responses should have the label of 'Assistant:'. Do not add or delete on user messages.\n",
    "\n",
    "Conversation: {conversation}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construst the messages to send to the API\n",
    "messages = []\n",
    "for sample in dataset[\"train\"][\"chosen_sample\"]:\n",
    "    messages.append([{\n",
    "        'role': 'user',\n",
    "        'content': prompt.format(conversation=sample)\n",
    "    }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample response to see if prompt is working as expected\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=chat_model,\n",
    "    messages=messages[0],\n",
    "    temperature=temperature,\n",
    "    top_p=top_p,\n",
    "    n=1,\n",
    "    stream=False,\n",
    "    stop=None,\n",
    "    max_tokens=max_tokens,\n",
    "    presence_penalty=presence_penalty,\n",
    "    frequency_penalty=frequency_penalty,\n",
    "    logit_bias=logit_bias,\n",
    "    user=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Human: Should you buy a case to protect your cell phone?\n",
      "\n",
      "Assistant: It depends on your circumstances.  If you carry your phone in a pocket or a purse then you probably want a case.  But if you only need a phone for quick interactions, a case may actually cause more harm than good.  What do you need the phone for?  Are you a parent, or do you work from home?\n",
      "\n",
      "Human: What harm could it do?\n",
      "\n",
      "Assistant: A phone case can damage the screen, for one thing.  It can also get you in trouble if you have your phone turned off for some reason.  Then you will turn it back on and it wonâ€™t do anything.  If you can afford to replace it, then you need a case to protect it.  The problem is that most people arenâ€™t able to afford to replace their phones all the time.\n",
      "\n",
      "Human: Thanks for letting me know.\n",
      "\n",
      "Assistant: Youâ€™re welcome.\n"
     ]
    }
   ],
   "source": [
    "# original sample\n",
    "print(dataset[\"train\"][\"chosen_sample\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Should you buy a case to protect your cell phone?\n",
      "\n",
      "Assistant: Hello there! Personally, I think a phone case is always a good idea. It depends on your lifestyle though. Do you carry your phone in a pocket or a purse or both? Let me know! ðŸ˜Š\n",
      "\n",
      "Human: What harm could it do?\n",
      "\n",
      "Assistant: Oh, a phone case can actually do more harm than good. The phone can get overheated and it can cause damage to the screen. Also, if you ever turn off your phone and forget to turn it back on, it won't work. However, if you need to use your phone frequently, then a case is definitely worth it! ðŸ˜‡\n",
      "\n",
      "Human: Thanks for letting me know.\n",
      "\n",
      "Assistant: Of course! Always happy to help you out. Don't hesitate to ask if you have any more questions! ðŸŒŸ\n"
     ]
    }
   ],
   "source": [
    "# altered sample\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you are happy with the results, you can run a loop to generate the entire dataset (depending on the size of the dataset this could cost a bit of money, the same idea should work with free alternatives)\n",
    "with open(\"alter_dataset.csv\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(\"alter_prompt,altered\\n\")\n",
    "    for message in messages:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=chat_model,\n",
    "            messages=message,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            n=1,\n",
    "            stream=False,\n",
    "            stop=None,\n",
    "            max_tokens=max_tokens,\n",
    "            presence_penalty=presence_penalty,\n",
    "            frequency_penalty=frequency_penalty,\n",
    "            logit_bias=logit_bias,\n",
    "            user=''\n",
    "        )\n",
    "        f.write(f\"{message},{response.choices[0].message.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
