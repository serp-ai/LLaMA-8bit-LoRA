# LLaMA-8bit-LoRA

Repository for training a LoRA for the LLaMA model on HuggingFace with 8-bit quantization. Research only.
<br>
ðŸ‘‰ [Join our Discord Server](https://serp.ly/@serpai/discord) for updates, support & collaboration
<br>

Dataset creation, training, weight merging, and quantization instructions are in the [docs](docs/).

# Check out our trained LoRAs on HuggingFace
## Anthropic's HH
- [7B](https://huggingface.co/serpdotai/llama-hh-lora-7B)
- [13B](https://huggingface.co/serpdotai/llama-hh-lora-13B)
- [30B](https://huggingface.co/serpdotai/llama-hh-lora-30B)
