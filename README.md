# Chat LLaMA 

8bit-LoRA or 4bit-LoRA

Repository for training a LoRA for the LLaMA (1 and 2) models on HuggingFace with 8-bit or 4-bit quantization. Research only for LLaMA 1, LLaMA 2 is open commercially.
<br><br><br>
ðŸ‘‰ [Join our Discord Server](https://serp.ly/@serpai/discord) for updates, support & collaboration
<br><br><br>

Dataset creation, training, weight merging, and quantization instructions are in the [docs](docs/).

# Check out our trained LoRAs on HuggingFace
## Anthropic's HH
- [7B](https://huggingface.co/serpdotai/llama-hh-lora-7B)
- [13B](https://huggingface.co/serpdotai/llama-hh-lora-13B)
- [30B](https://huggingface.co/serpdotai/llama-hh-lora-30B)
